{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmilijaSvirsk/DeepLearning-ImageSegmentation/blob/main/3lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49aa7ad9-b30e-410e-82de-55df2397c4bf",
        "outputId": "ac2f8852-f62d-4072-a0e6-7bbf4d75a8b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import albumentations as A\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {device}')\n"
      ],
      "id": "49aa7ad9-b30e-410e-82de-55df2397c4bf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j13hMngeEj4F",
        "outputId": "8f7da999-da27-4d29-cbc4-b6e95f2831e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "j13hMngeEj4F"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f61d03f-3522-47b2-86aa-4933c3a7ab01"
      },
      "source": [
        "## Dataset"
      ],
      "id": "6f61d03f-3522-47b2-86aa-4933c3a7ab01"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5298be9c-c5e1-4e2d-9212-8a4ed83796fd"
      },
      "outputs": [],
      "source": [
        "class PhotoDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root_dir, transforms):\n",
        "        self.transforms = transforms\n",
        "        self.img_dir = os.path.join(root_dir, 'CameraPng')\n",
        "        self.mask_dir = os.path.join(root_dir, 'CameraMask')\n",
        "\n",
        "        self.img_list = []\n",
        "        for fn in os.listdir(self.img_dir):\n",
        "            _, ext = os.path.splitext(fn)\n",
        "            if ext == '.png':\n",
        "                self.img_list.append(fn)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      img_name = os.path.join(self.img_dir, self.img_list[idx])\n",
        "      mask_name = os.path.join(self.mask_dir, self.img_list[idx])\n",
        "\n",
        "      img = np.array(Image.open(img_name))\n",
        "      mask = np.array(Image.open(mask_name))\n",
        "      if self.transforms is not None:\n",
        "            aug = self.transforms(image=img,mask=mask)\n",
        "            img = aug['image']\n",
        "            mask = aug['mask']\n",
        "            mask = torch.max(mask,dim=2)[0]\n",
        "      return img,mask"
      ],
      "id": "5298be9c-c5e1-4e2d-9212-8a4ed83796fd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceb3b902-3088-4757-94c6-e4f64f4f97a0"
      },
      "source": [
        "## Mokymo ir testavimo funkcijos"
      ],
      "id": "ceb3b902-3088-4757-94c6-e4f64f4f97a0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5ac1d6c-b2f3-4a45-9370-b6bea6deed64"
      },
      "outputs": [],
      "source": [
        "def seconds_to_time(seconds):\n",
        "    s = int(seconds) % 60\n",
        "    m = int(seconds) // 60\n",
        "    if m < 1:\n",
        "        return f'{s}s'\n",
        "    h = m // 60\n",
        "    m = m % 60\n",
        "    if h < 1:\n",
        "        return f'{m}m{s}s'\n",
        "    return f'{h}h{m}m{s}s'"
      ],
      "id": "a5ac1d6c-b2f3-4a45-9370-b6bea6deed64"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "678c2bdf-e53c-4c51-941b-93e7662278d6"
      },
      "outputs": [],
      "source": [
        "def train_epoch(optimizer, loss_func, scaler, model, loader):\n",
        "  model.train()\n",
        "  loss_acum = np.array([], dtype = np.float32)\n",
        "\n",
        "  for data in loader:\n",
        "    images = data[0].to(device)\n",
        "    mask = data[1].to(device)\n",
        "    mask = mask.type(torch.long)\n",
        "\n",
        "    with torch.cuda.amp.autocast():\n",
        "      pred = model(images)\n",
        "      loss = loss_func(pred, mask)\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    #scaler op? why?\n",
        "    scaler.scale(loss).backward()\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "\n",
        "    loss_acum = np.append(loss_acum, loss.cpu().detach().numpy())\n",
        "\n",
        "  return np.mean(loss_acum)"
      ],
      "id": "678c2bdf-e53c-4c51-941b-93e7662278d6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6621061f-b7d6-47bc-84ea-72e557eefe42"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader):\n",
        "  num_correct = 0\n",
        "  num_pixels = 0\n",
        "  dice_score = 0\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for img, mask in loader:\n",
        "          img = img.to(device)\n",
        "          mask = mask.to(device)\n",
        "\n",
        "          softmax = torch.nn.Softmax(dim=1)\n",
        "          preds = torch.argmax(softmax(model(img)),axis=1)\n",
        "\n",
        "          num_correct += (preds == mask).sum()\n",
        "          num_pixels += torch.numel(preds)\n",
        "          dice_score += (2 * (preds * mask).sum()) / ((preds + mask).sum() + 1e-8)\n",
        "\n",
        "  print(f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\")\n",
        "  print(f\"Dice score: {dice_score/len(loader)}\\n\")\n",
        "\n",
        "  mean = num_correct/num_pixels\n",
        "  mean = mean.cpu().detach().numpy()\n",
        "  return mean"
      ],
      "id": "6621061f-b7d6-47bc-84ea-72e557eefe42"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3045489e-c758-45df-9331-111fabadb9a2"
      },
      "outputs": [],
      "source": [
        "def train_and_eval(model, loader_train, loader_valid, epoch_count = 10, lr = 1e-3):\n",
        "  loss_func = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "  scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "  start_time = datetime.now()\n",
        "\n",
        "  train_iou_acum = []\n",
        "  valid_iou_acum = []\n",
        "  for epoch in range(epoch_count):\n",
        "    loss = train_epoch(optimizer, loss_func, scaler, model, loader_train)\n",
        "\n",
        "    train_iou = evaluate(model, loader_train)\n",
        "    train_iou_acum.append(train_iou)\n",
        "    valid_iou = evaluate(model, loader_valid)\n",
        "    valid_iou_acum.append(valid_iou)\n",
        "\n",
        "    current_time = datetime.now()\n",
        "    elapsed = seconds_to_time((current_time - start_time).total_seconds())\n",
        "    print(f'Epoch: {epoch}, Time: {elapsed}, Training loss: {loss}')\n",
        "    print(f'Training IoU: {(train_iou * 100)}, Validation IoU: {(valid_iou * 100)}')\n",
        "\n",
        "  return train_iou_acum, valid_iou_acum"
      ],
      "id": "3045489e-c758-45df-9331-111fabadb9a2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "016acc27-3c42-49aa-b8b2-9ec81c16c075"
      },
      "outputs": [],
      "source": [
        "def plot_iou(train_iou, valid_iou):\n",
        "  plt.clf()\n",
        "  plt.plot(train_iou, 'b', label = 'Training IoU')\n",
        "  plt.plot(valid_iou, 'r', label = 'Validation IoU')\n",
        "  plt.ylim(0.0, 1.0)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "id": "016acc27-3c42-49aa-b8b2-9ec81c16c075"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53accc14-f4af-4c39-8566-5898499d64e7"
      },
      "source": [
        "## Modelis ir duomenys"
      ],
      "id": "53accc14-f4af-4c39-8566-5898499d64e7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGTNtTLvMN-K"
      },
      "outputs": [],
      "source": [
        "class encoding_block(torch.nn.Module):\n",
        "    def __init__(self,in_channels, out_channels):\n",
        "        super(encoding_block,self).__init__()\n",
        "        model = []\n",
        "        model.append(torch.nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False))\n",
        "        model.append(torch.nn.BatchNorm2d(out_channels))\n",
        "        model.append(torch.nn.ReLU(inplace=True))\n",
        "        model.append(torch.nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False))\n",
        "        model.append(torch.nn.BatchNorm2d(out_channels))\n",
        "        model.append(torch.nn.ReLU(inplace=True))\n",
        "        self.conv = torch.nn.Sequential(*model)\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "id": "uGTNtTLvMN-K"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ob9hrTCwMUiA"
      },
      "outputs": [],
      "source": [
        "class unet_model(torch.nn.Module):\n",
        "    def __init__(self,out_channels=23,features=[64, 128, 256, 512]):\n",
        "        super(unet_model,self).__init__()\n",
        "        self.pool = torch.nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "        self.conv1 = encoding_block(3,features[0])\n",
        "        self.conv2 = encoding_block(features[0],features[1])\n",
        "        self.conv3 = encoding_block(features[1],features[2])\n",
        "        self.conv4 = encoding_block(features[2],features[3])\n",
        "        self.conv5 = encoding_block(features[3]*2,features[3])\n",
        "        self.conv6 = encoding_block(features[3],features[2])\n",
        "        self.conv7 = encoding_block(features[2],features[1])\n",
        "        self.conv8 = encoding_block(features[1],features[0])\n",
        "        self.tconv1 = torch.nn.ConvTranspose2d(features[-1]*2, features[-1], kernel_size=2, stride=2)\n",
        "        self.tconv2 = torch.nn.ConvTranspose2d(features[-1], features[-2], kernel_size=2, stride=2)\n",
        "        self.tconv3 = torch.nn.ConvTranspose2d(features[-2], features[-3], kernel_size=2, stride=2)\n",
        "        self.tconv4 = torch.nn.ConvTranspose2d(features[-3], features[-4], kernel_size=2, stride=2)\n",
        "        self.bottleneck = encoding_block(features[3],features[3]*2)\n",
        "        self.final_layer = torch.nn.Conv2d(features[0],out_channels,kernel_size=1)\n",
        "    def forward(self,x):\n",
        "        skip_connections = []\n",
        "        x = self.conv1(x)\n",
        "        skip_connections.append(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv2(x)\n",
        "        skip_connections.append(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv3(x)\n",
        "        skip_connections.append(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv4(x)\n",
        "        skip_connections.append(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.bottleneck(x)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "        x = self.tconv1(x)\n",
        "        x = torch.cat((skip_connections[0], x), dim=1)\n",
        "        x = self.conv5(x)\n",
        "        x = self.tconv2(x)\n",
        "        x = torch.cat((skip_connections[1], x), dim=1)\n",
        "        x = self.conv6(x)\n",
        "        x = self.tconv3(x)\n",
        "        x = torch.cat((skip_connections[2], x), dim=1)\n",
        "        x = self.conv7(x)\n",
        "        x = self.tconv4(x)\n",
        "        x = torch.cat((skip_connections[3], x), dim=1)\n",
        "        x = self.conv8(x)\n",
        "        x = self.final_layer(x)\n",
        "        return x"
      ],
      "id": "ob9hrTCwMUiA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0050a77f-7e62-486d-964a-35d6a1fc3ec4"
      },
      "outputs": [],
      "source": [
        "class FCNNet(torch.nn.Module):\n",
        "  def __init__(self, in_channels):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1_1 = torch.nn.Conv2d(in_channels, 16, (3, 3), padding = 'same')\n",
        "    self.relu1_1 = torch.nn.ReLU()\n",
        "    self.conv1_2 = torch.nn.Conv2d(16, 16, (3, 3), padding = 'same')\n",
        "    self.relu1_2 = torch.nn.ReLU()\n",
        "\n",
        "    self.pool2 = torch.nn.MaxPool2d((2, 2), (2, 2))\n",
        "    self.conv2_1 = torch.nn.Conv2d(16, 32, (3, 3), padding = 'same')\n",
        "    self.relu2_1 = torch.nn.ReLU()\n",
        "    self.conv2_2 = torch.nn.Conv2d(32, 32, (3, 3), padding = 'same')\n",
        "    self.relu2_2 = torch.nn.ReLU()\n",
        "\n",
        "    self.pool3 = torch.nn.MaxPool2d((2, 2), (2, 2))\n",
        "    self.conv3_1 = torch.nn.Conv2d(32, 64, (3, 3), padding = 'same')\n",
        "    self.relu3_1 = torch.nn.ReLU()\n",
        "    self.conv3_2 = torch.nn.Conv2d(64, 64, (3, 3), padding = 'same')\n",
        "    self.relu3_2 = torch.nn.ReLU()\n",
        "\n",
        "    self.pool4 = torch.nn.MaxPool2d((2, 2), (2, 2))\n",
        "    self.conv4_1 = torch.nn.Conv2d(64, 128, (3, 3), padding = 'same')\n",
        "    self.relu4_1 = torch.nn.ReLU()\n",
        "    self.conv4_2 = torch.nn.Conv2d(128, 128, (3, 3), padding = 'same')\n",
        "    self.relu4_2 = torch.nn.ReLU()\n",
        "    self.conv4_3 = torch.nn.Conv2d(128, 64, (3, 3), padding = 'same')\n",
        "    self.relu4_3 = torch.nn.ReLU()\n",
        "    self.upscale4 = torch.nn.Upsample(scale_factor = 2)\n",
        "\n",
        "    self.conv5_1 = torch.nn.Conv2d(64, 64, (3, 3), padding = 'same')\n",
        "    self.relu5_1 = torch.nn.ReLU()\n",
        "    self.conv5_2 = torch.nn.Conv2d(64, 32, (3, 3), padding = 'same')\n",
        "    self.relu5_2 = torch.nn.ReLU()\n",
        "    self.upscale5 = torch.nn.Upsample(scale_factor = 2)\n",
        "\n",
        "    self.conv6_1 = torch.nn.Conv2d(32, 32, (3, 3), padding = 'same')\n",
        "    self.relu6_1 = torch.nn.ReLU()\n",
        "    self.conv6_2 = torch.nn.Conv2d(32, 16, (3, 3), padding = 'same')\n",
        "    self.relu6_2 = torch.nn.ReLU()\n",
        "    self.upscale6 = torch.nn.Upsample(scale_factor = 2)\n",
        "\n",
        "    self.conv7_1 = torch.nn.Conv2d(16, 16, (3, 3), padding = 'same')\n",
        "    self.relu7_1 = torch.nn.ReLU()\n",
        "    self.conv7_2 = torch.nn.Conv2d(16, 16, (3, 3), padding = 'same')\n",
        "    self.relu7_2 = torch.nn.ReLU()\n",
        "\n",
        "    self.conv8 = torch.nn.Conv2d(16, 1, (1, 1))\n",
        "    self.sigmoid8 = torch.nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    block1 = torch.nn.Sequential(\n",
        "        self.conv1_1,\n",
        "        self.relu1_1,\n",
        "        self.conv1_2,\n",
        "        self.relu1_2\n",
        "    )(x)\n",
        "    block2 = torch.nn.Sequential(\n",
        "        self.pool2,\n",
        "        self.conv2_1,\n",
        "        self.relu2_1,\n",
        "        self.conv2_2,\n",
        "        self.relu2_2,\n",
        "    )(block1)\n",
        "    block3 = torch.nn.Sequential(\n",
        "        self.pool3,\n",
        "        self.conv3_1,\n",
        "        self.relu3_1,\n",
        "        self.conv3_2,\n",
        "        self.relu3_2,\n",
        "    )(block2)\n",
        "    block4 = torch.nn.Sequential(\n",
        "        self.pool4,\n",
        "        self.conv4_1,\n",
        "        self.relu4_1,\n",
        "        self.conv4_2,\n",
        "        self.relu4_2,\n",
        "        self.conv4_3,\n",
        "        self.relu4_3,\n",
        "        self.upscale4,\n",
        "    )(block3) + block3\n",
        "    block5 = torch.nn.Sequential(\n",
        "        self.conv5_1,\n",
        "        self.relu5_1,\n",
        "        self.conv5_2,\n",
        "        self.relu5_2,\n",
        "        self.upscale5,\n",
        "    )(block4) + block2\n",
        "    block6 = torch.nn.Sequential(\n",
        "        self.conv6_1,\n",
        "        self.relu6_1,\n",
        "        self.conv6_2,\n",
        "        self.relu6_2,\n",
        "        self.upscale6,\n",
        "    )(block5) + block1\n",
        "    block7 = torch.nn.Sequential(\n",
        "        self.conv7_1,\n",
        "        self.relu7_1,\n",
        "        self.conv7_2,\n",
        "        self.relu7_2,\n",
        "    )(block6)\n",
        "    block8 = torch.nn.Sequential(\n",
        "        self.conv8,\n",
        "        self.sigmoid8\n",
        "    )(block7)\n",
        "    return block8"
      ],
      "id": "0050a77f-7e62-486d-964a-35d6a1fc3ec4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f58387b-697a-410c-adc3-5bec61a87760"
      },
      "source": [
        "## Mokymas ir testavimas"
      ],
      "id": "1f58387b-697a-410c-adc3-5bec61a87760"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPC0C4W2MxqV"
      },
      "outputs": [],
      "source": [
        "transf = A.Compose([\n",
        "    A.Resize(160,240),\n",
        "    A.augmentations.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
        "    ToTensorV2()\n",
        "])"
      ],
      "id": "hPC0C4W2MxqV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8182d427-6021-4d25-9a6f-2ae28ac9bf9e",
        "outputId": "d1b1e5e1-177b-4a2a-e4d3-0c1941b43857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 100, Test: 100\n"
          ]
        }
      ],
      "source": [
        "train_dataset = PhotoDataset('drive/MyDrive/GMM_images/dataA',transf)\n",
        "valid_dataset = PhotoDataset('drive/MyDrive/GMM_images/dataB',transf)\n",
        "\n",
        "num_workers = 2\n",
        "batch_size = 10\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, num_workers = num_workers, shuffle = True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = 1, num_workers = num_workers, shuffle = False)\n",
        "\n",
        "print(f'Train: {len(train_dataset)}, Test: {len(valid_dataset)}')"
      ],
      "id": "8182d427-6021-4d25-9a6f-2ae28ac9bf9e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "e962e11e-e440-4079-be89-5a6c34746290",
        "outputId": "b2e72072-fb2f-4390-d2aa-71f4e5f398cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter count: 31,039,063\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Got 1195634/3840000 with acc 31.14\n",
            "Dice score: 5.988448619842529\n",
            "\n",
            "Got 1192262/3840000 with acc 31.05\n",
            "Dice score: 5.986215591430664\n",
            "\n",
            "Epoch: 0, Time: 10m21s, Training loss: 2.2197508811950684\n",
            "Training IoU: 31.136301159858704, Validation IoU: 31.04848861694336\n",
            "Got 1627608/3840000 with acc 42.39\n",
            "Dice score: 6.408050537109375\n",
            "\n",
            "Got 1623931/3840000 with acc 42.29\n",
            "Dice score: 6.409144401550293\n",
            "\n",
            "Epoch: 1, Time: 20m13s, Training loss: 1.420250654220581\n",
            "Training IoU: 42.3856258392334, Validation IoU: 42.28987097740173\n",
            "Got 3023533/3840000 with acc 78.74\n",
            "Dice score: 7.565220832824707\n",
            "\n",
            "Got 3015306/3840000 with acc 78.52\n",
            "Dice score: 7.558035850524902\n",
            "\n",
            "Epoch: 2, Time: 29m56s, Training loss: 0.977212131023407\n",
            "Training IoU: 78.73783707618713, Validation IoU: 78.52359414100647\n",
            "Got 3344035/3840000 with acc 87.08\n",
            "Dice score: 7.806251525878906\n",
            "\n",
            "Got 3341814/3840000 with acc 87.03\n",
            "Dice score: 7.797047138214111\n",
            "\n",
            "Epoch: 3, Time: 39m46s, Training loss: 0.6995503902435303\n",
            "Training IoU: 87.0842456817627, Validation IoU: 87.02640533447266\n",
            "Got 3408715/3840000 with acc 88.77\n",
            "Dice score: 7.878079414367676\n",
            "\n",
            "Got 3398790/3840000 with acc 88.51\n",
            "Dice score: 7.859959602355957\n",
            "\n",
            "Epoch: 4, Time: 49m38s, Training loss: 0.5474027395248413\n",
            "Training IoU: 88.76861929893494, Validation IoU: 88.51015567779541\n",
            "Got 3308328/3840000 with acc 86.15\n",
            "Dice score: 7.742919921875\n",
            "\n",
            "Got 3304999/3840000 with acc 86.07\n",
            "Dice score: 7.7458367347717285\n",
            "\n",
            "Epoch: 5, Time: 59m21s, Training loss: 0.45337867736816406\n",
            "Training IoU: 86.15437746047974, Validation IoU: 86.06768250465393\n"
          ]
        }
      ],
      "source": [
        "model = unet_model().to(device)\n",
        "print(f'Parameter count: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')\n",
        "\n",
        "train_iou, valid_iou = train_and_eval(model, train_loader, valid_loader, epoch_count = 10, lr = 1e-3)\n",
        "plot_iou(train_iou, valid_iou)"
      ],
      "id": "e962e11e-e440-4079-be89-5a6c34746290"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sIaVEcMY27J"
      },
      "source": [
        "#Statistics"
      ],
      "id": "2sIaVEcMY27J"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NuAAWLneYIdE"
      },
      "outputs": [],
      "source": [
        "def evaluate_with_stats(model, loader, stats):\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for img, mask in loader:\n",
        "          img = img.to(device)\n",
        "          mask = mask.to(device)\n",
        "\n",
        "          softmax = torch.nn.Softmax(dim=1)\n",
        "          preds = torch.argmax(softmax(model(img)),axis=1)\n",
        "\n",
        "          #flatten\n",
        "          mask = torch.flatten(mask)\n",
        "          preds = torch.flatten(preds)\n",
        "\n",
        "          #relocate to cpu\n",
        "          mask_arr = mask.cpu().detach().numpy()\n",
        "          pred_arr = preds.cpu().detach().numpy()\n",
        "          total_mask = torch.bincount(mask).cpu().detach().numpy()\n",
        "          total_pred = torch.bincount(preds).cpu().detach().numpy()\n",
        "\n",
        "          total_num = torch.numel(preds)\n",
        "\n",
        "          stats.appendConfusionMatrix(mask_arr, pred_arr, total_mask, total_pred, total_num)"
      ],
      "id": "NuAAWLneYIdE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ww9RAYNjEZBi"
      },
      "outputs": [],
      "source": [
        "class Statistics():\n",
        "  def __init__(self, class_number=13):\n",
        "    self.class_number = class_number\n",
        "    self.TP = np.zeros(class_number)\n",
        "    self.TN = np.zeros(class_number)\n",
        "    self.FP = np.zeros(class_number)\n",
        "    self.FN = np.zeros(class_number)\n",
        "\n",
        "    self.f1_micro = np.zeros(class_number)\n",
        "    self.f1_macro = 0\n",
        "\n",
        "  def appendConfusionMatrix(self, mask, pred, total_mask_b, total_pred_b, total_num):\n",
        "    TP = np.zeros(self.class_number)\n",
        "    TN = np.zeros(self.class_number)\n",
        "    FP = np.zeros(self.class_number)\n",
        "    FN = np.zeros(self.class_number)\n",
        "\n",
        "    mask_num = self.class_number-len(total_mask_b)\n",
        "    total_mask = np.pad(total_mask_b, (0, mask_num), mode='constant')\n",
        "\n",
        "    pred_num = self.class_number-len(total_pred_b)\n",
        "    total_pred = np.pad(total_pred_b, (0, pred_num), mode='constant')\n",
        "\n",
        "    for i in range(self.class_number):\n",
        "      TP[i] += self.count_matches(mask, pred, i)\n",
        "\n",
        "    #get FN\n",
        "    FN += total_pred - TP\n",
        "\n",
        "    #get FP\n",
        "    FP += total_mask - TP\n",
        "\n",
        "    #get TN\n",
        "    TN += np.full(self.class_number, total_num) - TP - FN - FP\n",
        "\n",
        "    self.TP += TP\n",
        "    self.TN += TN\n",
        "    self.FP += FP\n",
        "    self.FN += FN\n",
        "\n",
        "  def count_matches(self, list1, list2, num):\n",
        "    arr1 = np.array(list1)\n",
        "    arr2 = np.array(list2)\n",
        "    count = np.sum((arr1 == num) & (arr2 == num))\n",
        "    return count\n",
        "\n",
        "  def getConfusionMatrixClass(self, class_name):\n",
        "    return {\"TP\":self.TP[class_name],\"TN\":self.TN[class_name],\"FP\":self.FP[class_name],\"FN\":self.FN[class_name]}\n",
        "\n",
        "  def calcF1Statistics(self):\n",
        "    TP_arr = self.TP\n",
        "    TN_arr = self.TN\n",
        "    FP_arr = self.FP\n",
        "    FN_arr = self.FN\n",
        "    recall = 0\n",
        "    precision = 0\n",
        "    f1 = 0\n",
        "\n",
        "    #calc micro\n",
        "    for i in range(self.class_number):\n",
        "      TP = TP_arr[i]\n",
        "      TN = TN_arr[i]\n",
        "      FP = FP_arr[i]\n",
        "      FN = FN_arr[i]\n",
        "\n",
        "      if((TP + FN)==0):\n",
        "        recall = 0\n",
        "      else:\n",
        "        recall = TP / (TP + FN)\n",
        "\n",
        "      if((TP + FP)==0):\n",
        "        precision = 0\n",
        "      else:\n",
        "        precision = TP / (TP + FP)\n",
        "\n",
        "      if((precision + recall)==0):\n",
        "        f1 = 0\n",
        "      else:\n",
        "        f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "      self.f1_micro[i] = f1\n",
        "\n",
        "    #calc macro\n",
        "    self.f1_macro = np.sum(self.f1_micro)/self.class_number\n",
        "\n",
        "  def getF1Micro(self):\n",
        "    return self.f1_micro\n",
        "\n",
        "  def getF1Macro(self):\n",
        "    return self.f1_macro\n",
        "\n",
        "  def printF1Micro(self):\n",
        "    for i in range(self.class_number):\n",
        "      print(f'Class:{i} f1={self.f1_micro[i]}')\n",
        "\n"
      ],
      "id": "Ww9RAYNjEZBi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ttkE0-WjFg9F"
      },
      "outputs": [],
      "source": [
        "def testing(model, loader, stats):\n",
        "  evaluate_with_stats(model, loader, stats)"
      ],
      "id": "ttkE0-WjFg9F"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MDdkMb3Yg4fE"
      },
      "outputs": [],
      "source": [
        "stats = Statistics()\n",
        "testing(model, valid_loader, stats)\n",
        "stats.calcF1Statistics()"
      ],
      "id": "MDdkMb3Yg4fE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_QW4HlfyjmES"
      },
      "outputs": [],
      "source": [
        "print(stats.getConfusionMatrixClass(0))"
      ],
      "id": "_QW4HlfyjmES"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX7oY-FXFnGF"
      },
      "outputs": [],
      "source": [
        "print(\"F1-Micro\")\n",
        "stats.printF1Micro()\n",
        "print(\"\\nF1-Macro\")\n",
        "print(f'f1={stats.getF1Macro()}')"
      ],
      "id": "iX7oY-FXFnGF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mf78jZ51YSUu"
      },
      "outputs": [],
      "source": [
        "num_of_img = 3\n",
        "ind = 0\n",
        "for x,y in valid_loader:\n",
        "    x = x.to(device)\n",
        "    fig , ax =  plt.subplots(3, 3, figsize=(18, 18))\n",
        "    softmax = torch.nn.Softmax(dim=1)\n",
        "    preds = torch.argmax(softmax(model(x)),axis=1).to('cpu')\n",
        "    img1 = np.transpose(np.array(x[0,:,:,:].to('cpu')),(1,2,0))\n",
        "    preds1 = np.array(preds[0,:,:])\n",
        "    mask1 = np.array(y[0,:,:])\n",
        "\n",
        "    ax[0,0].set_title('Image')\n",
        "    ax[0,1].set_title('Prediction')\n",
        "    ax[0,2].set_title('Mask')\n",
        "\n",
        "    ax[0][0].axis(\"off\")\n",
        "    ax[1][0].axis(\"off\")\n",
        "    ax[2][0].axis(\"off\")\n",
        "\n",
        "    ax[0][0].imshow(img1)\n",
        "    ax[0][1].imshow(preds1)\n",
        "    ax[0][2].imshow(mask1)\n",
        "\n",
        "    ind+=1\n",
        "    if(ind == num_of_img):\n",
        "      break"
      ],
      "id": "mf78jZ51YSUu"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}